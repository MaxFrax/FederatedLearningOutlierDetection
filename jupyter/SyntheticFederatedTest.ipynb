{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac581f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from flod.classifiers.bsvclassifier import BSVClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90167340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contour(X, clf, colors):\n",
    "    # Creates a grid to fit all the data\n",
    "    gx = np.linspace(min(X[:,0])-.2, max(X[:,0])+.2, 50)\n",
    "    gy = np.linspace(min(X[:,1])-.2, max(X[:,1])+.2, 50)\n",
    "    gX, gY = np.meshgrid(gx, gy)\n",
    "    \n",
    "    # Evaluates the radious of each point in the 2 dimensional space\n",
    "    radiuses = [clf._compute_r(np.array([x, y])) for x, y in zip(np.ravel(gX), np.ravel(gY))]\n",
    "    zs = np.array(radiuses)\n",
    "    gZ = zs.reshape(gX.shape)\n",
    "    membership_contour = plt.contour(gX, gY, gZ, levels=(clf.radius_, ), colors='blue')\n",
    "    plt.clabel(membership_contour, inline=1)\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], c=colors, alpha=.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00037b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(clf, dataset):\n",
    "    mistakes = sum(clf.predict(X))\n",
    "    print(f'c: {clf.c}, q: {clf.q}')\n",
    "\n",
    "    sv_count = 0\n",
    "    bsv_count = 0\n",
    "    for b in clf.betas_:\n",
    "        if not np.isclose(b, 0) and not np.isclose(b, clf.c):\n",
    "                    sv_count+=1\n",
    "        if np.isclose(b, clf.c):\n",
    "                    bsv_count+=1\n",
    "\n",
    "    print(f'Support Vectors are {sv_count}, over {len(dataset)} candidates')\n",
    "    print(f'Bounded Support Vectors are {bsv_count}, over {len(dataset)} candidates')\n",
    "    print(f'Mistakes {mistakes}/{len(dataset)} = {mistakes/len(dataset)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9443fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zeros(y, y_pred, **kwargs):\n",
    "    return len(y)-sum(y_pred)\n",
    "\n",
    "scoring = {\n",
    "    'zeros_scorer': make_scorer(count_zeros)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a7aac0",
   "metadata": {},
   "source": [
    "# FLOD goes federated over synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a0350",
   "metadata": {},
   "source": [
    "In this notebook we want to answer the following question:\n",
    "\"Can the server build a sphere containing all the data since the dataset is distributed to all the clients and unkown to the server?\"\n",
    "\n",
    "There is a fundamental issue in this test:\n",
    "there are no outliers, so the naive 100% correct sphere would be the simplest and biggest one that can fit the space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9eae73",
   "metadata": {},
   "source": [
    "## 1. Single client scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b747e0",
   "metadata": {},
   "source": [
    "We generate a synthetic dataset. \n",
    "All the points have label 0, since 1 means the points is an outlier.\n",
    "\n",
    "With multiple centers, a low std is harder than a large one.\n",
    "\n",
    "I have tested with centers from 1 to 5 and with std up to 2.\n",
    "I also tried to raise the number of samples, but soon we hit the limit of how many points gurobi can handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafda4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=1000, centers=5, n_features=2, cluster_std=1.0)\n",
    "y = [0] * len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b8ceed",
   "metadata": {},
   "source": [
    "Let's see if we can create a sphere containing all the points with our implementation of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a22389",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'q': uniform(0.0001, 20),\n",
    "    'c': uniform()    \n",
    "}\n",
    "clf = RandomizedSearchCV(BSVClassifier(), params, cv=2, n_jobs=-1, scoring=scoring, refit='zeros_scorer', return_train_score=False, n_iter=15)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ec3e3",
   "metadata": {},
   "source": [
    "Theoretically, in the following plot there should be only one color, the one representing the points classified to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = clf.best_estimator_\n",
    "\n",
    "plot_contour(X, best_clf, best_clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(best_clf, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc60a1",
   "metadata": {},
   "source": [
    "Some times even this baseline does around 20% of mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a936643",
   "metadata": {},
   "source": [
    "## 2. Multiple client scenario\n",
    "\n",
    "Let's split randomly the data generated before among k clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e67634",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = 5\n",
    "points_per_client = int(len(X) / clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c78813",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [X[i*points_per_client: (i+1)*points_per_client] for i in range(clients)]\n",
    "\n",
    "colors = [int(i/points_per_client) for i in range(len(X))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a91dda",
   "metadata": {},
   "source": [
    "Let's plot again the previous plot, but this time the colors represent the client assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = clf.best_estimator_\n",
    "plot_contour(X, best_clf, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce4cc9",
   "metadata": {},
   "source": [
    "### Federated primitives\n",
    "\n",
    "#### 1. Init server model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_server_model():\n",
    "    return {\n",
    "        'q': 1,\n",
    "        'C': 1,\n",
    "        'betas': np.empty(shape=(0, 2)),\n",
    "        'xs': np.empty(shape=(0, 2))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa40b00",
   "metadata": {},
   "source": [
    "#### 2. Client update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_compute_update(global_model, client_data):\n",
    "    # Concat points from server and from client\n",
    "    X = np.concatenate((global_model['xs'], client_data))\n",
    "    # Init the classifier with q and C from server\n",
    "    clf = BSVClassifier(q=global_model['q'], c=global_model['C'])\n",
    "    # Train locally\n",
    "    clf.fit(X, [0]*len(X))\n",
    "    # Select only the positive betas related from client_data\n",
    "    client_betas = clf.betas_[len(global_model['xs']):]\n",
    "    assert(len(client_betas) == len(client_data))\n",
    "    \n",
    "    for i, t in enumerate(zip(client_betas, client_data)):\n",
    "        b, x = t\n",
    "        if not np.isclose(b, 0):\n",
    "            yield x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d1330",
   "metadata": {},
   "source": [
    "#### 3. Server combines client updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5935ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_combine(global_model, client_updates):\n",
    "    # Concatenates server points and clients candidate points.\n",
    "    X = np.concatenate((global_model['xs'], *client_updates))\n",
    "    \n",
    "    # Performs model selection over this new dataset\n",
    "    # Cross validation is low because I want to fit exactly the data I have got\n",
    "    clf = RandomizedSearchCV(BSVClassifier(), params, cv=2, n_jobs=-1, scoring=scoring, refit='zeros_scorer', return_train_score=False, n_iter=15)\n",
    "    clf.fit(X, [0] * len(X))\n",
    "    \n",
    "    # Filter and keep only the support vectors\n",
    "    xs = []\n",
    "    betas = []\n",
    "    for i, t in enumerate(zip(clf.best_estimator_.betas_, X)):\n",
    "        b, x = t\n",
    "        if not np.isclose(b, 0):\n",
    "            xs.append(x)\n",
    "            betas.append(b)\n",
    "            \n",
    "    return {\n",
    "        'q': clf.best_estimator_.q,\n",
    "        'C': clf.best_estimator_.c,\n",
    "        'betas': betas,\n",
    "        'xs': xs\n",
    "    }, clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad3762",
   "metadata": {},
   "source": [
    "## Federated Learning simulation with one pass on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebefaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "number_of_rounds = 20\n",
    "\n",
    "server_model = init_server_model()\n",
    "\n",
    "# Metrics\n",
    "debug_sk_models = []\n",
    "debug_models = []\n",
    "mistakes = []\n",
    "\n",
    "client_updates = []\n",
    "\n",
    "points_per_round = int(points_per_client / number_of_rounds)\n",
    "\n",
    "def client_worker(client, round_ix):\n",
    "    dataset = k[client]\n",
    "    # Pick a data slice\n",
    "    dataset = dataset[points_per_round*round_ix : points_per_round*(round_ix+1),:]\n",
    "    update = client_compute_update(server_model, dataset)\n",
    "    update = np.array(list(update))\n",
    "    if update.size > 0:\n",
    "        client_updates.append(update)\n",
    "\n",
    "for r in tqdm(range(number_of_rounds)):\n",
    "    client_updates = []\n",
    "    #threads = []\n",
    "    for client in range(clients):\n",
    "        client_worker(client, r)\n",
    "        #t = threading.Thread(target=client_worker, args=(client, r))\n",
    "        #threads.append(t)\n",
    "        #t.start()\n",
    "        \n",
    "    #for t in threads:\n",
    "        #t.join()\n",
    "        \n",
    "    server_model, debug_model = global_combine(server_model, client_updates)\n",
    "    mistakes.append(sum(debug_model.predict(X)))\n",
    "    debug_models.append(server_model)\n",
    "    debug_sk_models.append(debug_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be91e4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_contour(X, debug_model, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f88ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(debug_model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400de134",
   "metadata": {},
   "source": [
    "**How does the mistakes ratio change during optimization?**\n",
    "\n",
    "At each round we collect data about the mistakes of the model over the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677d1fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([len(s['betas']) for s in debug_models], label='support vectors')\n",
    "plt.plot(mistakes, label='mistakes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67594a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Average mistakes: {np.average(mistakes)}')\n",
    "print(f'Std mistakes: {np.std(mistakes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed0256",
   "metadata": {},
   "source": [
    "Usually the standard deviation is very high, probabily keeping track of the best model so far is a good idea.\n",
    "\n",
    "How can we evaluate which model is the best in so far in production since we have limited view about the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334ff96",
   "metadata": {},
   "source": [
    "### How does the best classifier found during the process work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mistakes = min(mistakes)\n",
    "best_mistakes_index = mistakes.index(best_mistakes)\n",
    "\n",
    "print(f'Best mistakes {best_mistakes}/{len(X)} = {best_mistakes/len(X)*100}% at round {best_mistakes_index}/{number_of_rounds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d082733",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(X, debug_sk_models[best_mistakes_index], colors)\n",
    "print_report(debug_sk_models[best_mistakes_index], X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a487a",
   "metadata": {},
   "source": [
    "## Federated Learning simulation with multiple pass on data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8db6c",
   "metadata": {},
   "source": [
    "Does seing the data multiple times reduce mistakes? It's a sort of overfit\n",
    "So at line 17, instead of taking the following slice of data, we sample the client's data randomly at each iteration.\n",
    "\n",
    "It can happen that the same data is seen multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ddd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rounds_sampling = 70\n",
    "\n",
    "server_model_sampling = init_server_model()\n",
    "\n",
    "# Metrics\n",
    "debug_sk_models_sampling = []\n",
    "debug_models_sampling = []\n",
    "mistakes_sampling = []\n",
    "\n",
    "client_updates = []\n",
    "\n",
    "points_per_round_sampling = points_per_round\n",
    "\n",
    "def client_worker_sampling(client, round_ix):\n",
    "    dataset = k[client]\n",
    "    # Randomly sample the client data\n",
    "    random_batch = np.random.choice(dataset.shape[0], points_per_round_sampling) \n",
    "    dataset = dataset[random_batch]\n",
    "    \n",
    "    update = client_compute_update(server_model_sampling, dataset)\n",
    "    update = np.array(list(update))\n",
    "    if update.size > 0:\n",
    "        client_updates.append(update)\n",
    "\n",
    "for r in tqdm(range(number_of_rounds_sampling)):\n",
    "    client_updates = []\n",
    "    #threads = []\n",
    "    for client in range(clients):\n",
    "        client_worker_sampling(client, r)\n",
    "        #t = threading.Thread(target=client_worker_sampling, args=(client, r))\n",
    "        #threads.append(t)\n",
    "        #t.start()\n",
    "        \n",
    "    #for t in threads:\n",
    "        #t.join()\n",
    "        \n",
    "    server_model_sampling, debug_model = global_combine(server_model, client_updates)\n",
    "    mistakes_sampling.append(sum(debug_model.predict(X)))\n",
    "    debug_models_sampling.append(server_model)\n",
    "    debug_sk_models_sampling.append(debug_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250cdd3",
   "metadata": {},
   "source": [
    "The pink line shows the number of iterations at which the \"single pass on data\" simulation ended. (previous experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe406c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Mistakes {mistakes_sampling[-1]}/{len(X)} = {mistakes_sampling[-1]/len(X)*100}%')\n",
    "\n",
    "plt.plot([len(s['betas']) for s in debug_models_sampling], label='support vectors')\n",
    "plt.plot(mistakes_sampling, label='mistakes')\n",
    "plt.axvline(number_of_rounds, alpha=.4, color='purple')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average mistakes: {np.average(mistakes_sampling)}')\n",
    "print(f'Std mistakes: {np.std(mistakes_sampling)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c704f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(X, debug_sk_models_sampling[-1], colors)\n",
    "print_report(debug_sk_models_sampling[-1], X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d411ff7d",
   "metadata": {},
   "source": [
    "### How does the best classifier found during the process work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mistakes = min(mistakes_sampling)\n",
    "best_mistakes_index = mistakes_sampling.index(best_mistakes)\n",
    "\n",
    "print(f'Best mistakes {best_mistakes}/{len(X)} = {best_mistakes/len(X)*100}% at round {best_mistakes_index}/{number_of_rounds_sampling}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd00b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(X, debug_sk_models_sampling[best_mistakes_index], colors)\n",
    "print_report(debug_sk_models_sampling[best_mistakes_index], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5309fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
